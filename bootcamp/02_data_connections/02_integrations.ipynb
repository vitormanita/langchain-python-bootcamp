{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4513def5-073f-47f8-b509-356af5cad2dd",
   "metadata": {},
   "source": [
    "# Integrations\n",
    "\n",
    "Document loaders labeled as \"integrations\" can essentially be thought of as the same as normal document loaders, but they are integrated with some specific 3rd party, such as Google Cloud, or even specific websites, like Wikipedia.\n",
    "\n",
    "https://python.langchain.com/docs/integrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "059619f6-e3a3-498c-9db0-10dd06bca361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example where we load a post on Hacker News website\n",
    "from langchain.document_loaders import HNLoader\n",
    "\n",
    "loader = HNLoader(\"https://news.ycombinator.com/item?id=36697119\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5592cee2-6e26-4932-abf4-ab1af9905346",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79937c08-0d27-46fd-9651-174ed57d5604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "endisneigh 54 days ago  \n",
      "             | next [–] \n",
      "\n",
      "I wish the folks who clearly do not like Google would just not use their products instead of spamming every thread about how they will kill the product, true or not.——Anyway,It’s not clear which model they’re using for this. I assume whatever Bard is using, but who knows. This is relevant because depending on the intended experience the latency will matter.Overall it’s not a bad idea, but I do wonder what the monetization path will be for Google. I imagine this will be part of workspace. Perhaps they will add more tiers to include these offerings.I wish they shared a bit about how this will be differentiated from Bard. Is this simply a new front end to Bard? It’s really an open question. I haven’t seen many products that use LLMs that are better than the prompt response UX.The most interesting thing about this blog post is the “source grounding.” I’m curious if there’s actual engineering behind it, or is it prompt tweaking contextualized behind the scenes on a given doc.\n"
     ]
    }
   ],
   "source": [
    "print(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59ce819c-167f-4a21-86fd-3713ebcb7938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://news.ycombinator.com/item?id=36697119', 'title': 'NotebookLM: An AI Notebook'}\n"
     ]
    }
   ],
   "source": [
    "print(data[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cae599f-7534-41ea-af0c-1a51b579206c",
   "metadata": {},
   "source": [
    "## Summary of post with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22bd2152-efb7-4db3-9d82-2cc4960c1066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "\n",
    "key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4867708d-2aa2-4cd4-b3c1-baad7f018aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_prompt = HumanMessagePromptTemplate.from_template(\n",
    "    \"Please give me a short summary of the following HackerNews comment:\\n{comment}\"\n",
    ")\n",
    "chat_prompt = ChatPromptTemplate.from_messages([human_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88825678-138e-4680-a264-777451010f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1abed0b8-73ce-42d1-9e5e-e5af10727c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model(chat_prompt.format_prompt(comment=data[0].page_content).to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bc19246-8c12-48be-ac97-71a7c07aefb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The commenter expresses a wish for people who dislike Google to refrain from spamming negative comments about the company. They then discuss the uncertainty regarding which model Google is using for their product and how latency will impact the user experience. The commenter wonders about the monetization strategy for Google and speculates that this product may be part of their workspace offering. They also express curiosity about how this product will differentiate from another Google tool called Bard, particularly in terms of the use of Language Model Models (LLMs). The commenter finds the concept of \"source grounding\" mentioned in the blog post to be the most interesting aspect and questions whether it involves actual engineering or prompt tweaking.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
